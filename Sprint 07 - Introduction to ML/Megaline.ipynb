{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "\n",
    "Mobile carrier Megaline has found out that many of their subscribers use legacy plans. They want to develop a model that would analyze subscribers' behavior and recommend one of Megaline's newer plans: Smart or Ultra.\n",
    "\n",
    "You have access to behavior data about subscribers who have already switched to the new plans (from the project for the Statistical Data Analysis course). For this classification task, you need to develop a model that will pick the right plan. Since youâ€™ve already performed the data preprocessing step, you can move straight to creating the model.\n",
    "\n",
    "Develop a model with the highest possible _accuracy_. In this project, the threshold for _accuracy_ is 0.75. Check the _accuracy_ using the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening and looking through the data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries relevant to the project\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the csv\n",
    "df = pd.read_csv('users_behavior.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "# Taking a closer look at the dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>58.0</td>\n",
       "      <td>344.56</td>\n",
       "      <td>21.0</td>\n",
       "      <td>15823.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>57.0</td>\n",
       "      <td>431.64</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3738.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15.0</td>\n",
       "      <td>132.40</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21911.60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.0</td>\n",
       "      <td>43.39</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2538.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>90.0</td>\n",
       "      <td>665.41</td>\n",
       "      <td>38.0</td>\n",
       "      <td>17358.61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0\n",
       "5   58.0   344.56      21.0  15823.37         0\n",
       "6   57.0   431.64      20.0   3738.90         1\n",
       "7   15.0   132.40       6.0  21911.60         0\n",
       "8    7.0    43.39       3.0   2538.67         1\n",
       "9   90.0   665.41      38.0  17358.61         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Taking a closer look at the dataframe\n",
    "df.describe()\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting source data into training set, validation set, and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1928, 4)\n",
      "(1928,)\n",
      "(643, 4)\n",
      "(643,)\n",
      "(643, 4)\n",
      "(643,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into training and testing and validation sets at a ratio of 3:1:1 or 60%:20%:20%\n",
    "\n",
    "# Defining features and target\n",
    "features = df.drop(['is_ultra'], axis=1)\n",
    "target = df['is_ultra']\n",
    "\n",
    "# Splitting the data into a training and testing set\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2, random_state=12345)\n",
    "\n",
    "# Splitting the data into a validation set\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(features_train, target_train, test_size=0.25, random_state=12345)\n",
    "\n",
    "print(features_train.shape)\n",
    "print(target_train.shape)\n",
    "print(features_valid.shape)\n",
    "print(target_valid.shape)\n",
    "print(features_test.shape)\n",
    "print(target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating the Quality of Different Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 1 : 0.7387247278382582\n",
      "max_depth = 2 : 0.7573872472783826\n",
      "max_depth = 3 : 0.7651632970451011\n",
      "max_depth = 4 : 0.7636080870917574\n",
      "max_depth = 5 : 0.7589424572317263\n"
     ]
    }
   ],
   "source": [
    "# Model 1: Decsion Tree Classifier, tuning max_depth parameter\n",
    "\n",
    "for depth in range(1,6):\n",
    "    model = DecisionTreeClassifier(random_state=12345, max_depth=depth)\n",
    "    model.fit(features_train, target_train) # training the model\n",
    "    predictions_valid = model.predict(features_valid)\n",
    "    print(\"max_depth =\", depth, \": \", end='')\n",
    "    print(accuracy_score(target_valid, predictions_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest accuracy score of any Deceision Tree Classifier model was at max_depth = 3 : 0.7651632970451011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the best model on the validation set (n_estimators = 44): 0.7947122861586314\n"
     ]
    }
   ],
   "source": [
    "# Model 2: Random Forest Classifier, tuning the n_estimators parameter\n",
    "\n",
    "best_score = 0\n",
    "best_est = 0\n",
    "for est in range(1, 50): # hyperparameter range\n",
    "    model = RandomForestClassifier(random_state=12345, n_estimators=est) # set number of trees\n",
    "    model.fit(features_train, target_train) # training model on the training set\n",
    "    score = model.score(features_valid, target_valid) #calculating the accuracy score on the validation test set\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_est = est\n",
    "\n",
    "print(\"Accuracy of the best model on the validation set (n_estimators = {}): {}\".format(best_est, best_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the logistic regression model on the training set: 0.7422199170124482\n",
      "Accuracy of the logistic regression model on the validation set: 0.7293934681181959\n"
     ]
    }
   ],
   "source": [
    "# Model 3: Logistic Regression \n",
    "\n",
    "model = LogisticRegression(random_state=54321, solver='liblinear')\n",
    "model.fit(features_train, target_train) # training model on the training set\n",
    "score_train = model.score(features_train, target_train) # calculating accuracy score on training set\n",
    "score_valid = model.score(features_valid, target_valid) # calculating accuracy score on validation set\n",
    "\n",
    "print(\n",
    "    \"Accuracy of the logistic regression model on the training set:\", score_train)\n",
    "\n",
    "print(\n",
    "    \"Accuracy of the logistic regression model on the validation set:\", score_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the Quality of the Model Using the Test Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of the Final Model: 0.7916018662519441\n"
     ]
    }
   ],
   "source": [
    "# Appling Random Forest Classifier to Test Set\n",
    "\n",
    "test_model = RandomForestClassifier(random_state=12345, n_estimators=44)\n",
    "test_model.fit(features_train, target_train) # Training the model on the training set\n",
    "test_model_predictions = test_model.predict(features_test)\n",
    "test_model_accuracy = accuracy_score(target_test, test_model_predictions)\n",
    "\n",
    "print(f'Accuracy Score of the Final Model:', test_model_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the three classification models, the highest accuracy score on the validation set was found using the RandomForestClassifier, which yielded a 79.47% accuracy when n_estimators = 44. The DecisionTreeClassifier yielded an accuracy of 76.5% on the validation set, at a max depth of 3, the models highest accuracy. The lowest accuracy score came using Logistic Regression, which scored 72.9%. \n",
    "\n",
    "While the RandomForestClassifer had the best results, it is also the slowest and only beat out the DecisionTreeClassifier by a few percentage points. \n",
    "\n",
    "The accuracy of the RandomForestClassifer on the test set yielded a 79.16% score (when n_estimators = 44). Thus, Megaline is advised to utilize the RandomForestClassifier model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
